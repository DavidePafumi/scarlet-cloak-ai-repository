# -*- coding: utf-8 -*-
"""AI_scores_visualisation_pycode.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Dd9Z6jvXEDiMnEhzHMoJo8OZ8-zUyrKd
"""

# Defining the O_Donnell dataset with various categories and their values
O_Donnell = {
    "Original": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "0",
        "Readability": "27.6",
        "SAT (%)": "3.7",
        "Simplicity": "42.1",
        "Perplexity": "55.5",
        "Burstiness": "285.9",
        "Avg. Sentence Length": "25.5"
    },
    "EditPad": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "2",
        "Readability": "17.7",
        "SAT (%)": "3.6",
        "Simplicity": "41.6",
        "Perplexity": "190.2",
        "Burstiness": "321.6",
        "Avg. Sentence Length": "30.9"
    },
    "Writefull": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "2",
        "Readability": "27.3",
        "SAT (%)": "3.1",
        "Simplicity": "39.7",
        "Perplexity": "59.7",
        "Burstiness": "298.9",
        "Avg. Sentence Length": "22.7"
    },
    "Grammarly": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "0",
        "Readability": "33.0",
        "SAT (%)": "3.7",
        "Simplicity": "40.2",
        "Perplexity": "70.8",
        "Burstiness": "373.1",
        "Avg. Sentence Length": "16.5"
    },
    "GPT 3.5": {
        "Turnitin Score (%)": "11",
        "GPT Zero Score (%)": "65",
        "Readability": "8.1",
        "SAT (%)": "5.1",
        "Simplicity": "34.3",
        "Perplexity": "72.2",
        "Burstiness": "143.3",
        "Avg. Sentence Length": "23.1"
    },
    "GPT 4": {
        "Turnitin Score (%)": "56",
        "GPT Zero Score (%)": "90",
        "Readability": "7.7",
        "SAT (%)": "5.1",
        "Simplicity": "29.3",
        "Perplexity": "81.9",
        "Burstiness": "65.3",
        "Avg. Sentence Length": "17.5"
    },
    "Microsoft Bing Copilot": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "1",
        "Readability": "28.6",
        "SAT (%)": "3.5",
        "Simplicity": "41.9",
        "Perplexity": "53.6",
        "Burstiness": "284.8",
        "Avg. Sentence Length": "25.3"
    }
}

O_Donnell

# Defining the Perrault dataset with various categories and their values
Perrault = {
    "Original": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "0",
        "Readability": "74.3",
        "SAT (%)": "0.6",
        "Simplicity": "40.3",
        "Perplexity": "50.8",
        "Burstiness": "118.8",
        "Avg. Sentence Length": "18.3"
    },
    "EditPad": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "33",
        "Readability": "68.2",
        "SAT (%)": "1.9",
        "Simplicity": "39.5",
        "Perplexity": "112.4",
        "Burstiness": "4701.4",
        "Avg. Sentence Length": "19.7"
    },
    "Writefull": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "1",
        "Readability": "74.2",
        "SAT (%)": "0.5",
        "Simplicity": "38.7",
        "Perplexity": "55.7",
        "Burstiness": "85.0",
        "Avg. Sentence Length": "16.3"
    },
    "Grammarly": {
        "Turnitin Score (%)": "11",
        "GPT Zero Score (%)": "33",
        "Readability": "70.2",
        "SAT (%)": "0.8",
        "Simplicity": "39.4",
        "Perplexity": "48.0",
        "Burstiness": "103.3",
        "Avg. Sentence Length": "18.3"
    },
    "GPT 3.5": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "86",
        "Readability": "63.8",
        "SAT (%)": "1.2",
        "Simplicity": "35.4",
        "Perplexity": "51.7",
        "Burstiness": "213.8",
        "Avg. Sentence Length": "16.2"
    },
    "GPT 4": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "48",
        "Readability": "64.0",
        "SAT (%)": "0.6",
        "Simplicity": "33.0",
        "Perplexity": "116.0",
        "Burstiness": "386.8",
        "Avg. Sentence Length": "13.1"
    },
    "Microsoft Bing Copilot": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "0",
        "Readability": "81.5",
        "SAT (%)": "0.5",
        "Simplicity": "43.2",
        "Perplexity": "43.3",
        "Burstiness": "58.8",
        "Avg. Sentence Length": "17.5"
    }
}

Perrault

# Defining the Robinson dataset with various categories and their values
Robinson = {
    "Original": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "0",
        "Readability": "28.1",
        "SAT (%)": "4.2",
        "Simplicity": "34.1",
        "Perplexity": "62.7",
        "Burstiness": "64.1",
        "Avg. Sentence Length": "18.1"
    },
    "EditPad": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "0",
        "Readability": "18.3",
        "SAT (%)": "4.7",
        "Simplicity": "34.4",
        "Perplexity": "172.0",
        "Burstiness": "469.4",
        "Avg. Sentence Length": "19.4"
    },
    "Writefull": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "11",
        "Readability": "22.7",
        "SAT (%)": "2.8",
        "Simplicity": "31.4",
        "Perplexity": "71.1",
        "Burstiness": "79.4",
        "Avg. Sentence Length": "17.1"
    },
    "Grammarly": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "32",
        "Readability": "21.1",
        "SAT (%)": "5.1",
        "Simplicity": "36.7",
        "Perplexity": "65.8",
        "Burstiness": "76.1",
        "Avg. Sentence Length": "22.4"
    },
    "GPT 3.5": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "48",
        "Readability": "10.5",
        "SAT (%)": "3.8",
        "Simplicity": "26.6",
        "Perplexity": "73.2",
        "Burstiness": "66.1",
        "Avg. Sentence Length": "19.0"
    },
    "GPT 4": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "48",
        "Readability": "10.6",
        "SAT (%)": "4.9",
        "Simplicity": "21.9",
        "Perplexity": "89.8",
        "Burstiness": "123.1",
        "Avg. Sentence Length": "15.2"
    },
    "Microsoft Bing Copilot": {
        "Turnitin Score (%)": "0",
        "GPT Zero Score (%)": "0",
        "Readability": "27.7",
        "SAT (%)": "3.3",
        "Simplicity": "33.7",
        "Perplexity": "59.5",
        "Burstiness": "52.7",
        "Avg. Sentence Length": "18.1"
    }
}

Robinson

# Import necessary libraries
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

## Convert dictionaries to pandas DataFrame
# Convert O_Donnell
df_odonnell = pd.DataFrame(O_Donnell).T
# Convert Perrault
df_perrault = pd.DataFrame(Perrault).T
# Convert Robinson
df_robinson = pd.DataFrame(Robinson).T

# Convert all columns to numeric in all DataFrames
for df in [df_odonnell, df_perrault, df_robinson]:
    for column in df.columns:
        df[column] = pd.to_numeric(df[column], errors='coerce')

# Check the data types
print(df_odonnell.dtypes)
print(df_perrault.dtypes)
print(df_robinson.dtypes)

# Selecting specific columns
selected_columns = ['Readability', 'Simplicity', 'Perplexity', 'Burstiness']

# Apply selection to each DataFrame
df_odonnell_selected = df_odonnell[selected_columns]
df_perrault_selected = df_perrault[selected_columns]
df_robinson_selected = df_robinson[selected_columns]

# Displaying the selected DataFrames to verify the selection
print("O'Donnell Selected DataFrame:")
print(df_odonnell_selected)
print("\nPerrault Selected DataFrame:")
print(df_perrault_selected)
print("\nRobinson Selected DataFrame:")
print(df_robinson_selected)

# Plotting Heatmaps for each selected dataset
fig, axs = plt.subplots(3, 1, figsize=(12, 18))

# O'Donnell Dataset Heatmap
sns.heatmap(df_odonnell_selected, annot=True, fmt=".1f", cmap="Reds", ax=axs[0], vmin=35, center = 80, vmax = 200) #GPTZero tresholds
axs[0].set_title('O\'Donnell Dataset Heat Map')
axs[0].set_xticklabels(df_odonnell_selected.columns, rotation=45)
axs[0].set_yticklabels(df_odonnell_selected.index, rotation=0)

# Perrault Dataset Heatmap
sns.heatmap(df_perrault_selected, annot=True, fmt=".1f", cmap="Reds", ax=axs[1], vmin=35, center = 80, vmax = 200) #GPTZero tresholds
axs[1].set_title('Perrault Dataset Heat Map')
axs[1].set_xticklabels(df_perrault_selected.columns, rotation=45)
axs[1].set_yticklabels(df_perrault_selected.index, rotation=0)

# Robinson Dataset Heatmap
sns.heatmap(df_robinson_selected, annot=True, fmt=".1f", cmap="Reds", ax=axs[2], vmin=35, center = 80, vmax = 200) #GPTZero tresholds
axs[2].set_title('Robinson Dataset Heat Map')
axs[2].set_xticklabels(df_robinson_selected.columns, rotation=45)
axs[2].set_yticklabels(df_robinson_selected.index, rotation=0)

plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.patches import Patch

# Define SAT percentage categories and colors
sat_detailed_category_colors = {'below 2%': 'lightgreen', 'equal or above to 2%': 'yellow', 'above 4%': 'red'} # Based on GPT-3 thresholds

def plot_dataframe(df, dataset_name):
    # Create a custom legend for the detailed SAT categories
    sat_detailed_legend_elements = [Patch(facecolor=sat_detailed_category_colors[cat], label=cat) for cat in sat_detailed_category_colors]

    # Create subplots
    fig, axs = plt.subplots(2, 1, figsize=(10, 12))

    # First subplot for Line Plot of Average Sentence Length
    axs[0].plot(tools, average_sentence_lengths, color='grey', marker='o', linestyle='-', label='Avg. Sentence Length')  # Change to line plot
    axs[0].set_title(f'Avg. Sentence Length by Tool ({dataset_name})')
    axs[0].set_ylabel('Avg. Sentence Length')

    # Second subplot for SAT % with more detailed categorized colors
    axs[1].bar(tools, sat_percentages, color=sat_detailed_bar_colors)
    axs[1].set_title(f'SAT % by Tool ({dataset_name})')
    axs[1].set_ylabel('Percent SAT')
    axs[1].legend(handles=sat_detailed_legend_elements, title='SAT Categories')  # Use the SAT categories legend

    plt.tight_layout()
    plt.show()

# List of DataFrames
dfs = [df_odonnell, df_perrault, df_robinson]
dataset_names = ['O\'Donnell', 'Perrault', 'Robinson']

# Iterate through DataFrames
for df_selected, dataset_name in zip(dfs, dataset_names):
    # Select columns 'SAT (%)' and 'Avg. Sentence Length'
    df_selected = df_selected[['SAT (%)', 'Avg. Sentence Length']]

    # Extract data for plotting
    average_sentence_lengths = df_selected['Avg. Sentence Length']
    sat_percentages = df_selected['SAT (%)']

    # Assign colors for the detailed SAT categories
    sat_detailed_categories = ['below 2%' if x < 2
                               else 'equal or above to 2%'
                               if x >= 2 and x <= 4 else 'above 4%'
                               for x in df_selected['SAT (%)']]
    sat_detailed_bar_colors = [sat_detailed_category_colors[cat]
                               for cat in sat_detailed_categories]

    # Create a list of tools (based on the index of the df)
    tools = df_selected.index

    # Call the plotting function for each DataFrame with the dataset name
    plot_dataframe(df_selected, dataset_name)

# Updating the list of selected columns
selected_columns_percentage = ['Turnitin Score (%)', 'GPT Zero Score (%)', 'Readability', 'Simplicity', 'Perplexity', 'Burstiness']

# Apply selection to each DataFrame
df_odonnell_selected_percentage = df_odonnell[selected_columns]
df_perrault_selected_percentage = df_perrault[selected_columns]
df_robinson_selected_percentage = df_robinson[selected_columns]

# Displaying the selected DataFrames to verify the selection
print("O'Donnell Selected DataFrame:")
print(df_odonnell_selected)
print("\nPerrault Selected DataFrame:")
print(df_perrault_selected)
print("\nRobinson Selected DataFrame:")
print(df_robinson_selected)

# Plotting area graphs for each DataFrame
fig, axs = plt.subplots(3, 1, figsize=(12, 18))

# Define custom colors
colors = ['skyblue', 'salmon']  # First color for 'Turnitin Score (%)', second for 'GPT Zero Score (%)'

# O'Donnell Dataset Area Graph
df_odonnell[['Turnitin Score (%)', 'GPT Zero Score (%)']].plot.area(ax=axs[0], alpha=0.5, color=colors)
axs[0].set_title("O'Donnell Dataset - Turnitin vs GPT Zero Scores")
axs[0].set_ylabel("Score (%)")
axs[0].set_ylim(0, 150)  # Set y-axis limit

# Perrault Dataset Area Graph
df_perrault[['Turnitin Score (%)', 'GPT Zero Score (%)']].plot.area(ax=axs[1], alpha=0.5, color=colors)
axs[1].set_title("Perrault Dataset - Turnitin vs GPT Zero Scores")
axs[1].set_ylabel("Score (%)")
axs[1].set_ylim(0, 150)  # Set y-axis limit

# Robinson Dataset Area Graph
df_robinson[['Turnitin Score (%)', 'GPT Zero Score (%)']].plot.area(ax=axs[2], alpha=0.5, color=colors)
axs[2].set_title("Robinson Dataset - Turnitin vs GPT Zero Scores")
axs[2].set_ylabel("Score (%)")
axs[2].set_ylim(0, 150)  # Set y-axis limit

# Adjust layout and show plot
plt.tight_layout()
plt.show()

